<section xml:id="caseStudyMalariaVaccine">
  <title>Case study: malaria vaccine (special topic)</title>
  <introduction>
    <p>
      How large does an observed difference need to be for it to provide convincing evidence that something real is going on,
      something beyond random variation?
      Answering this question requires the tools that we will encounter in the later chapters on probability and inference.
      However, this is such an interesting and important question,
      and we'll also address it here using simulation.
      This section can be covered now or in tandem with <xref ref="ch_foundations_for_inf">Chapter</xref>: Foundations for Inference.
    </p>
  </introduction>
  <subsection>
    <title>Learning objectives</title>
    <ol>
      <li>
        <p>
          Recognize that an observed difference in sample statistics may be due to random chance and that we use hypothesis testing to determine if this difference statistically significant (i.e. too large to be attributed to random chance).
        </p>
      </li>
      <li>
        <p>
          Set up competing hypotheses and use the results of a simulation to evaluate the degree of support the data provide against the null hypothesis and for the alternative hypothesis.
        </p>
      </li>
    </ol>
  </subsection>
  <subsection xml:id="variabilityWithinData">
    <title>Variability within data</title>
    <p>
          <idx><h>data</h><h>malaria vaccine</h></idx>
    </p>
    <example xml:id="classRightLeftSideApple">
      <statement>
        <p>
          Suppose your professor splits the students in class into two groups:
          students on the left and students on the right.
          If <m>\hat{p}_{_L}</m> and
          <m>\hat{p}_{_R}</m> represent the proportion of students who own an Apple product on the left and right,
          respectively,
          would you be surprised if <m>\hat{p}_{_L}</m> did not {exactly} equal <m>\hat{p}_{_R}</m>?
        </p>
      </statement>
      <answer>
        <p>
          While the proportions would probably be close to each other,
          it would be unusual for them to be exactly the same.
          We would probably observe a small difference due to {chance}.
        </p>
      </answer>
    </example>
    <exercise>
      <statement>
        <p>
          If we don't think the side of the room a person sits on in class is related to whether the person owns an Apple product,
          what assumption are we making about the relationship between these two variables?
        </p>
      </statement>
      <answer>
        <p>
          We would be assuming that these two variables are independent.
        </p>
      </answer>
    </exercise>
    <p>
      We consider a study on a new malaria vaccine called PfSPZ. In this study,
      volunteer patients were randomized into one of two experiment groups: 14 patients received an experimental vaccine or 6 patients received a placebo vaccine.
      Nineteen weeks later,
      all 20 patients were exposed to a drug-sensitive malaria virus strain;
      the motivation of using a drug-sensitive strain of virus here is for ethical considerations,
      allowing any infections to be treated effectively.
      The results are summarized in <xref ref="malaria_vaccine_20_exp_summary">Figure</xref>,
      where 9 of the 14 treatment patients remained free of signs of infection while all of the<nbsp/>6 patients in the control group patients showed some baseline signs of infection.
    </p>
    <figure xml:id="malaria_vaccine_20_exp_summary">
      <caption>Summary results for the malaria vaccine experiment.</caption>
      <tabular>
        <row>
          <cell></cell>
          <cell></cell>
          <cell>\multicolumn{2}{c}{<c>outcome</c>}</cell>
        </row>
        <row>
          <cell></cell>
          <cell></cell>
          <cell>{infection}</cell>
          <cell>{no infection}</cell>
          <cell>Total</cell>
          <cell>\hspace{3mm}</cell>
        </row>
        <row>
          <cell></cell>
          <cell>{vaccine}</cell>
          <cell>\malariaAA</cell>
          <cell>\malariaAB</cell>
          <cell>\malariaAD</cell>
        </row>
        <row>
          <cell><c>treatment</c></cell>
          <cell>{placebo}</cell>
          <cell>\malariaBA</cell>
          <cell>\malariaBB</cell>
          <cell>\malariaBD</cell>
        </row>
        <row>
          <cell></cell>
          <cell>Total</cell>
          <cell>\malariaDA</cell>
          <cell>\malariaDB</cell>
          <cell>\malariaDD</cell>
        </row>
        <row>
          <cell></cell>
        </row>
      </tabular>
    </figure>
    <exercise>
      <statement>
        <p>
          Is this an observational study or an experiment?
          What implications does the study type have on what can be inferred from the results?
        </p>
      </statement>
      <answer>
        <p>
          The study is an experiment,
          as patients were randomly assigned an experiment group.
          Since this is an experiment,
          the results can be used to evaluate a causal relationship between the malaria vaccine and whether patients showed signs of an infection.
        </p>
      </answer>
    </exercise>
    <p>
      In this study,
      a smaller proportion of patients who received the vaccine showed signs of an infection (35.7% versus 100%).
      However, the sample is very small,
      and it is unclear whether the difference provides
      <em>convincing evidence</em>
      that the vaccine is effective.
    </p>
    <example>
      <statement>
        <p>
          Data scientists are sometimes called upon to evaluate the strength of evidence.
          When looking at the rates of infection for patients in the two groups in this study,
          what comes to mind as we try to determine whether the data show convincing evidence of a real difference?
        </p>
      </statement>
      <solution xml:id="malaria_vaccine_20_what_is_convincing">
        <p>
          The observed infection rates (35.7% for the treatment group versus 100% for the control group) suggest the vaccine may be effective.
          However, we cannot be sure if the observed difference represents the vaccine's efficacy or is just from random chance.
          Generally there is a little bit of fluctuation in sample data,
          and we wouldn't expect the sample proportions to be <em>exactly</em> equal,
          even if the truth was that the infection rates were independent of getting the vaccine.
          Additionally, with such small samples,
          perhaps it's common to observe such large differences when we randomly split a group due to chance alone!
        </p>
      </solution>
    </example>
    <p>
      <xref ref="malaria_vaccine_20_what_is_convincing">Example</xref>
      is a reminder that the observed outcomes in the data sample may not perfectly reflect the true relationships between variables since there is
      <term>random noise</term>.
      While the observed difference in rates of infection is large,
      the sample size for the study is small,
      making it unclear if this observed difference represents efficacy of the vaccine or whether it is simply due to chance.
      We label these two competing claims,
      <m>H_0</m> and <m>H_A</m>, which are spoken as
      <q>H-nought</q>
      and
      <q>H-A</q>:
      <ul>
        <li>
          <title>invalidlabel</title>
          <p>
            <em>Independence model.</em> The variables <c>treatment</c> and <c>outcome</c> are independent.
            They have no relationship,
            and the observed difference between the proportion of patients who developed an infection in the two groups, 64.3%, was due to chance.
          </p>
        </li>
        <li>
          <title>invalidlabel</title>
          <p>
            <em>Alternative model.</em> The variables are
            <em>not</em> independent.
            The difference in infection rates of 64.3% was not due to chance,
            and vaccine affected the rate of infection.
          </p>
        </li>
      </ul>
    </p>
    <p>
      What would it mean if the independence model,
      which says the vaccine had no influence on the rate of infection, is true?
      It would mean 11<nbsp/>patients were going to develop an infection
      <em>no matter which group they were randomized into</em>,
      and 9<nbsp/>patients would not develop an infection
      <em>no matter which group they were randomized into</em>.
      That<nbsp/>is,
      if the vaccine did not affect the rate of infection,
      the difference in the infection rates was due to chance alone in how the patients were randomized.
    </p>
    <p>
      Now consider the alternative model:
      infection rates were influenced by whether a patient received the vaccine or not.
      If this was true, and especially if this influence was substantial,
      we would expect to see some difference in the infection rates of patients in the groups.
    </p>
    <p>
      We choose between these two competing claims by assessing if the data conflict so much with <m>H_0</m> that the independence model cannot be deemed reasonable.
      If this is the case, and the data support <m>H_A</m>,
      then we will reject the notion of independence and conclude there was discrimination.
    </p>
  </subsection>
  <subsection xml:id="simulatingTheStudy">
    <title>Simulating the study</title>
    <p>
      We're going to implement <em>simulations</em>,
          <idx><h>simulation</h></idx>
      where we will pretend we know that the malaria vaccine being tested does <em>not</em> work.
      Ultimately, we want to understand if the large difference we observed is common in these simulations.
      If it is common,
      then maybe the difference we observed was purely due to chance.
      If it is very uncommon,
      then the possibility that the vaccine was helpful seems more plausible.
    </p>
    <p>
      <xref ref="malaria_vaccine_20_exp_summary">Figure</xref>
      shows that 11 patients developed infections and 9 did not.
      For our simulation,
      we will suppose the infections were independent of the vaccine and we were able to <em>rewind</em>
      back to when the researchers randomized the patients in the study.
      If we happened to randomize the patients differently,
      we may get a different result in this hypothetical world where the vaccine doesn't influence the infection.
      Let's complete another <term>randomization</term> using a simulation.
    </p>
    <p>
      In this <term>simulation</term>,
      we take 20 notecards to represent the 20 patients, where we write down
      <q>infection</q>
      on 11 cards and
      <q>no infection</q>
      on 9 cards.
      In this hypothetical world,
      we believe each patient that got an infection was going to get it regardless of which group they were in,
      so let's see what happens if we randomly assign the patients to the treatment and control groups again.
      We thoroughly shuffle the notecards and deal 14 into a <c>vaccine</c> pile and 6 into a <c>placebo</c> pile.
      Finally, we tabulate the results,
      which are shown in <xref ref="malaria_vaccine_20_exp_summary_rand_1">Figure</xref>.
    </p>
    <figure xml:id="malaria_vaccine_20_exp_summary_rand_1">
      <caption>Simulation results, where any difference
      in infection rates is purely due to chance.</caption>
      <tabular>
        <row>
          <cell></cell>
          <cell></cell>
          <cell>\multicolumn{2}{c}{<c>outcome</c>}</cell>
        </row>
        <row>
          <cell></cell>
          <cell></cell>
          <cell>{infection}</cell>
          <cell>{no infection}</cell>
          <cell>Total</cell>
          <cell>\hspace{3mm}</cell>
        </row>
        <row>
          <cell>treatment</cell>
          <cell>{vaccine}</cell>
          <cell>7</cell>
          <cell>7</cell>
          <cell>14</cell>
        </row>
        <row>
          <cell>(simulated)</cell>
          <cell>{placebo}</cell>
          <cell>4</cell>
          <cell>2</cell>
          <cell>6</cell>
        </row>
        <row>
          <cell></cell>
          <cell>Total</cell>
          <cell>11</cell>
          <cell>9</cell>
          <cell>20</cell>
        </row>
        <row>
          <cell></cell>
        </row>
      </tabular>
    </figure>
    <exercise xml:id="malaria_vaccine_20_exp_summary_rand_1_diff">
      <statement>
        <p>
          What is the difference in infection rates between the two simulated groups in <xref ref="malaria_vaccine_20_exp_summary_rand_1">Figure</xref>?
          How does this compare to the observed 64.3% difference in the actual data?
        </p>
      </statement>
      <answer>
        <p>
          <m>4 / 6 - 7 / 14 = 0.167</m> or about 16.7% in favor of the vaccine.
          This difference due to chance is much smaller than the difference observed in the actual groups.
        </p>
      </answer>
    </exercise>
  </subsection>
  <subsection>
    <title>Checking for independence</title>
    <p>
      We computed one possible difference under the independence model in Guided <xref ref="malaria_vaccine_20_exp_summary_rand_1_diff">Practice</xref>,
      which represents one difference due to chance.
      While in this first simulation,
      we physically dealt out notecards to represent the patients,
      it is more efficient to perform this simulation using a computer.
      Repeating the simulation on a computer,
      we get another difference due to chance:
      <md>
        <mrow>\frac{2}{\malariaBD{}} - \frac{9}{\malariaAD{}} = -0.310</mrow>
      </md>
    </p>
    <p>
      And another:
      <md>
        <mrow>\frac{3}{\malariaBD{}} - \frac{8}{\malariaAD{}} = -0.071</mrow>
      </md>
    </p>
    <p>
      And so on until we repeat the simulation enough times that we have a good idea of what represents the
      <em>distribution of differences from chance alone</em>.
      <xref ref="malaria_rand_dot_plot">Figure</xref>
      shows a stacked plot of the differences found from 100 simulations,
      where each dot represents a simulated difference between the infection rates
      (control rate minus treatment rate).
    </p>
    <figure xml:id="malaria_rand_dot_plot">
      <caption>A stacked dot plot of differences from
      100 simulations produced under the independence model,
      <m>H_0</m>, where in these simulations infections are
      unaffected by the vaccine.
      Two of the 100 simulations had a difference of
      at least \malariaIRDiffPerc, the difference observed
      in the study.</caption>
      \Figure{0.74}{malaria_rand_dot_plot}
    </figure>
    <p>
      Note that the distribution of these simulated differences is centered around 0.
      We simulated these differences assuming that the independence model was true,
      and under this condition,
      we expect the difference to be near zero with some random fluctuation,
      where <em>near</em> is pretty generous in this case since the sample sizes are so small in this study.
    </p>
    <example>
      <statement>
        <p>
          Given the results of the simulation shown in <xref ref="malaria_rand_dot_plot">Figure</xref>,
          about how often would you expect to observe a result as large as 64.3% if <m>H_0</m> were true?
        </p>
      </statement>
      <answer>
        <p>
          Because a result this large happened 2 times out the 100 simulations,
          we would expect such a large value only 2% of the time if <m>H_0</m> were true.
        </p>
      </answer>
    </example>
    <p>
      There are two possible interpretations of the results of the study:
      <ul>
        <li>
          <title>invalidlabel</title>
          <p>
            <em>Independence model.</em> The vaccine has no effect on infection rate,
            and we just happened to observe a rare event.
          </p>
        </li>
        <li>
          <title>invalidlabel</title>
          <p>
            <em>Alternative model.</em> The vaccine has an effect on infection rate,
            and the difference we observed was actually due to the vaccine being effective at combatting malaria,
            which explains the large difference of<nbsp/>64.3%.
          </p>
        </li>
      </ul>
    </p>
    <p>
      Based on the simulations,
      we have two options. (1)<nbsp/>We conclude that the study results do not provide strong enough evidence against the independence model,
      meaning we do not conclude that the vaccine had an effect in this clinical setting. (2)<nbsp/>We conclude the evidence is sufficiently strong to reject <m>H_0</m>,
      and we assert that the vaccine was useful.
    </p>
    <p>
      Is 2% small enough to make us reject the independence model?
      That depends on how much evidence we require.
      The smaller that probability is,
      the more evidence it provides against <m>H_0</m>.
      Later, we will see that researchers often use a cutoff of 5%, though it can depend upon the situation.
      Using the 5% cutoff,
      we would reject the independence model in favor of the alternative.
      That is, we are concluding the data provide strong evidence that the vaccine provides some protection against malaria in this clinical setting.
    </p>
    <p>
      When there is strong enough evidence that the result points to a real difference and is not simply due to random variation,
      we call the result <term>statistically significant</term>.
    </p>
    <p>
          <idx><h>data</h><h>malaria vaccine</h></idx>
    </p>
    <p>
      One field of statistics, statistical inference,
      is built on evaluating whether such differences are due to chance.
      In statistical inference,
      data scientists evaluate which model is most reasonable given the data.
      Errors do occur, just like rare events,
      and we might choose the wrong model.
      While we do not always choose correctly,
      statistical inference gives us tools to control and evaluate how often these errors occur.
      In <xref ref="foundationsForInference">Chapter</xref>,
      we give a formal introduction to the problem of model selection.
      We spend the next two chapters building a foundation of probability and theory necessary to make that discussion rigorous.
    </p>
  </subsection>
</section>