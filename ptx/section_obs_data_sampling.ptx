<section xml:id="section_obs_data_sampling">
  <title>Observational studies and sampling strategies</title>
  <introduction>
    <p>
      You have probably read or heard claims from many studies and polls.
      A<nbsp/>background in statistical reasoning will help you assess the validity of such claims.
      Some of the big questions we address in this section include:
      <ul>
        <li>
          <p>
            If a study finds a relationship between two variables,
            such as eating chocolate and positive health outcomes,
            is it reasonable to conclude eating chocolate improves health outcomes?
          </p>
        </li>
        <li>
          <p>
            How do opinion polls work?
            How do research organizations collect the data,
            and what types of bias should we look out for?
          </p>
        </li>
      </ul>
    </p>
  </introduction>
  <subsection>
    <title>Learning objectives</title>
    <ol>
      <li>
        <p>
          Identify possible confounding factors in a study and explain,
          in context, how they could confound.
        </p>
      </li>
      <li>
        <p>
          Distinguish among and describe a convenience sample,
          a volunteer sample, and a random sample.
        </p>
      </li>
      <li>
        <p>
          Identify and describe the effects of different types of bias in sample surveys,
          including undercoverage, non-response, and response bias.
        </p>
      </li>
      <li>
        <p>
          Identify and describe how to implement different random sampling methods,
          including simple, systematic, stratified, and cluster.
        </p>
      </li>
      <li>
        <p>
          Recognize the benefits and drawbacks of choosing one sampling method over another.
        </p>
      </li>
      <li>
        <p>
          Understand when it valid to generalize and to what population that generalization can be made.
        </p>
      </li>
    </ol>
  </subsection>
  <subsection>
    <title>Observational studies</title>
    <p>
      Generally, data in observational studies are collected only by monitoring what occurs,
      while experiments require the primary explanatory variable in a study be assigned for each subject by the researchers.
    </p>
    <p>
      Making causal conclusions based on experiments is often reasonable.
      However, making the same causal conclusions based on observational data is treacherous and is not recommended.
      Observational studies are generally only sufficient to show associations.
    </p>
    <exercise xml:id="sunscreenLurkingExample">
      <statement>
        <p>
          Suppose an observational study tracked sunscreen use and skin cancer,
          and it was found people who use sunscreen are more likely to get skin cancer than people who do not use sunscreen.
          Does this mean sunscreen <em>causes</em> skin cancer?
        </p>
      </statement>
      <answer>
        <p>
          No.
          See the paragraph following the exercise for an explanation.
        </p>
      </answer>
    </exercise>
    <p>
      Some previous research tells us that using sunscreen actually reduces skin cancer risk,
      so maybe there is another variable that can explain this hypothetical association between sunscreen usage and skin cancer.
      One important piece of information that is absent is sun exposure.
      Sun exposure is what is called a
      <term>confounding variable</term>
      (also called a <term>lurking variable</term>,
      <term>confounding factor</term>,
      or a <term>confounder</term>).
      <image width="56%" source="images/sunCausesCancer.png" />
    </p>
    <assemblage>
      <title>Confounding variable</title>
      <p>
        A confounding variable is a variable that is associated with both the explanatory
        <em>and</em> response variables.
        Because of the confounding variable's association with both variables,
        we do not know if the response is due to the explanatory variable or due to the confounding variable.
      </p>
    </assemblage>
    <p>
      Sun exposure is a confounding factor because it is associated with both the use of sunscreen and the development of skin cancer.
      People who are out in the sun all day are more likely to use sunscreen,
      and people who are out in the sun all day are more likely to get skin cancer.
      Research shows us the development of skin cancer is due to the sun exposure.
      The variables of sunscreen usage and sun exposure are <term>confounded</term>,
      and without this research,
      we would have no way of knowing which one was the true cause of skin cancer.
    </p>
    <example>
      <statement>
        <p>
          In a study that followed 1,169 non-diabetic men and women who had been hospitalized for a first heart attack,
          the people that reported eating chocolate had increased survival rate over the next 8 years than those that reported not eating chocolate.
          Also, those who ate more chocolate also tended to live longer on average.
          The researched controlled for several confounding factors,
          such as age,
          physical activity, smoking, and many other factors.
          Can we conclude that the consumption of chocolate caused the people to live longer?
        </p>
      </statement>
      <solution xml:id="confounding_2008_chocolate_health_study">
        <p>
          This is an observational study,
          not a controlled randomized experiment.
          Even though the researchers controlled for many possible variables,
          there may still be other confounding factors. (Can you think of any that weren't mentioned?) While it is possible that the chocolate had an effect,
          this study cannot prove that chocolate increased the survival rate of patients.
        </p>
      </solution>
    </example>
    <example>
      <statement>
        <p>
          The authors who conducted the study did warn in the article that additional studies would be necessary to determine whether the correlation between chocolate consumption and survival translates to any causal relationship.
          That is, they acknowledged that there may be confounding factors.
          One possible confounding factor not considered was mental health.
          In context, explain what it would mean for mental health to be a confounding factor in this study.
        </p>
      </statement>
      <solution>
        <p>
          Mental health would be a confounding factor if, for example,
          people with better mental health tended to eat more chocolate,
          and those with better mental health <em>also</em>
          were less likely to die within the 8 year study period.
          Notice that if better mental health were not associated with eating more chocolate,
          it would not be considered a confounding factor since it wouldn't explain the observed associated between eating chocolate and having a better survival rate.
          If better mental health were associated only with eating chocolate and not with a better survival rate,
          then it would also not be confounding for the same reason.
          Only if a variable that is associated with both the explanatory variable of interest (chocolate) and the outcome variable in the study
          (survival during the 8 year study period)
          can it be considered a confounding factor.
        </p>
      </solution>
    </example>
    <p>
      While one method to justify making causal conclusions from observational studies is to exhaust the search for confounding variables,
      there is no guarantee that all confounding variables can be examined or measured.
    </p>
    <p>
      In the same way,
      the <c>county</c> data set is an observational study with confounding variables,
      and its data cannot be used to make causal conclusions.
    </p>
    <exercise>
      <statement>
        <p>
          <xref ref="multiunitsVsOwnership">Figure</xref>
          shows a negative association between the homeownership rate and the percentage of multi-unit structures in a county.
          However, it is unreasonable to conclude that there is a causal relationship between the two variables.
          Suggest one or more other variables that might explain the relationship visible in <xref ref="multiunitsVsOwnership">Figure</xref>.
        </p>
      </statement>
      <answer>
        <p>
          Answers will vary.
          Population density may be important.
          If a county is very dense,
          then this may require a larger fraction of residents to live in multi-unit structures.
          Additionally,
          the high density may contribute to increases in property value,
          making homeownership infeasible for many residents.
        </p>
      </answer>
    </exercise>
    <p>
      Observational studies come in two forms:
      prospective and retrospective studies.
      A <term>prospective study</term> identifies individuals and collects information as events unfold.
      For instance,
      medical researchers may identify and follow a group of similar individuals over many years to assess the possible influences of behavior on cancer risk.
      One example of such a study is The Nurses' Health Study,
      started in 1976 and expanded in 1989.<fn>
      XXoiRedirect{textbook-channing_nurse_study}{**}XX
      </fn> This prospective study recruits registered nurses and then collects data from them using questionnaires.
      <em>Retrospective studies</em>
          <idx><h>retrospective studies</h></idx>
      collect data after events have taken place,
      e.g. researchers may review past events in medical records.
      Some data sets,
      such as <c>county</c>,
      may contain both prospectively- and retrospectively-collected variables.
      Local governments prospectively collect some variables as events unfolded (e.g. retails sales) while the federal government retrospectively collected others during the 2010 census (e.g. county population counts).
    </p>
  </subsection>
  <subsection>
    <title>Sampling from a population</title>
    <p>
          <idx><h>sample</h><h>random sample</h></idx>
    </p>
    <p>
      We might try to estimate the time to graduation for Duke undergraduates in the last 5 years by collecting a sample of students.
      All graduates in the last 5 years represent the <em>population</em>,
          <idx><h>population</h></idx>
      and graduates who are selected for review are collectively called the <em>sample</em>.
          <idx><h>sample</h></idx>
      The goal is to use information from the sample to generalize or make an inference to the population.
      In order to be able to generalize,
      we must <em>randomly</em> select a sample from the population of interest.
      The most basic type of random selection is equivalent to how raffles are conducted.
      For example, in selecting graduates,
      we could write each graduate's name on a raffle ticket and draw 100 tickets.
      The selected names would represent a random sample of 100 graduates.
    </p>
    <figure xml:id="popToSampleGraduates">
      <caption>In this graphic, five graduates are randomly selected from the population to be included in the sample.</caption>
      <image width="47%" source="images/popToSampleGraduates.png" />
    </figure>
    <p>
      Why pick a sample randomly?
      Why not just pick a sample by hand?
      Consider the following scenario.
    </p>
    <example>
      <statement>
        <p>
          Suppose we ask a student who happens to be majoring in nutrition to select several graduates for the study.
          What kind of students do you think she might select?
          Do you think her sample would be representative of all graduates?
        </p>
      </statement>
      <solution>
        <p>
          Perhaps she would pick a disproportionate number of graduates from health-related fields.
          Or perhaps her selection would be well-representative of the population.
          When selecting samples by hand,
          we run the risk of picking a <em>biased</em> sample,
          even if that bias is unintentional or difficult to discern.
        </p>
      </solution>
    </example>
    <figure xml:id="popToSubSampleGraduates">
      <caption>Instead of sampling from all graduates equally, a nutrition major might inadvertently pick graduates with health-related majors disproportionately often.</caption>
      <image width="47%" source="images/popToSubSampleGraduates.png" />
    </figure>
    <p>
      If the student majoring in nutrition picked a disproportionate number of graduates from health-related fields,
      this would introduce undercoverage bias into the sample.
      <em>Undercoverage bias</em>
          <idx><h>undercoverage bias</h></idx>
      occurs when some individuals of the population are inherently less likely to be included in the sample than others,
      making the sample not representative of the population.
      In the example,
      this bias creates a problem because a degree in health-related fields might take more or less time to complete than a degree in other fields.
      Suppose that it takes longer.
      Since graduates from other fields would be less likely to be in the sample,
      the undercoverage bias would cause her to
      <em>overestimate</em> the parameter.
    </p>
    <p>
      Sampling randomly resolves the problem of undercoverage bias,
      <em>if the sample is randomly selected from the entire population of interest</em>.
      If the sample is randomly selected from only a subset of the population, say,
      only graduates from health-related fields,
      then the sample will not be representative of the population of interest.
      Generalizations can only be made to the population from which the sample is randomly selected.
    </p>
    <p>
      The most basic random sample is called a
      <term>simple random sample</term>,
      which is equivalent to using a raffle to select cases.
      This means that each case in the population has an equal chance of being included and there is no implied connection between the cases in the sample.
    </p>
    <p>
      A common downfall is a <term>convenience sample</term>,
          <idx><h>sample</h><h>convenience sample</h></idx>
      where individuals who are easily accessible are more likely to be included in the sample.
      For instance,
      if a political survey is done by stopping people walking in the Bronx,
      this will not represent all of New York City.
      It is often difficult to discern what sub-population a convenience sample represents.
    </p>
    <figure xml:id="surveySample">
      <caption>Due to the possibility of non-response, surveys studies may only reach a certain group within the population. It is difficult, and often times impossible, to completely fix this problem.</caption>
      <image width="50%" source="images/surveySample.png" />
    </figure>
    <p>
      Similarly, a <term>volunteer sample</term>
      is one in which people's responses are solicited and those who choose to participate, respond.
      This is a problem because those who choose to participate may tend to have different opinions than the rest of the population,
      resulting in a biased sample.
    </p>
    <exercise>
      <statement>
        <p>
          We can easily access ratings for products, sellers,
          and companies through websites.
          These ratings are based only on those people who go out of their way to provide a rating.
          If 50% of online reviews for a product are negative,
          do you think this means that 50% of buyers are dissatisfied with the product?
        </p>
      </statement>
      <answer>
        <p>
          Answers will vary.
          From our own anecdotal experiences,
          we believe people tend to rant more about products that fell below expectations than rave about those that perform as expected.
          For this reason,
          we suspect there is a negative bias in product ratings on sites like Amazon.
          However, since our experiences may not be representative,
          we also keep an open mind.
        </p>
      </answer>
    </exercise>
    <p>
      The act of taking a random sample helps minimize bias;
      however, bias can crop up in other ways.
      Even when people are picked at random, e.g. for surveys,
      caution must be exercised if the <term>non-response</term>
          <idx><h>sample</h><h>non-response</h></idx>
      is high.
      For instance,
      if only 30% of the people randomly sampled for a survey actually respond,
      then it is unclear whether the results are
      <term>representative</term>
      of the entire population.
      This <term>non-response bias</term>
          <idx><h>sample</h><h>non-response bias</h></idx>
      can skew results.
    </p>
    <p>
      Even if a sample has no undercoverage bias and no non-response bias,
      there is an additional type of bias that often crops up and undermines the validity of results,
      known as response bias.
      <em>Response bias</em>
          <idx><h>response bias</h></idx>
      refers to a broad range of factors that influence how a person responds,
      such as question wording, question order,
      and influence of the interviewer.
      This type of bias can be present even when we collect data from an entire population in what is called a <term>census</term>.
      Because response bias is often subtle,
      one must pay careful attention to how questions were asked when attempting to draw conclusions from the data.
    </p>
    <example>
      <statement>
        <p>
          Suppose a high school student wants to investigate the student body's opinions on the food in the cafeteria.
          Let's assume that she manages to survey every student in the school.
          How might response bias arise in this context?
        </p>
      </statement>
      <solution>
        <p>
          There are many possible correct answers to this question.
          For example,
          students might respond differently depending upon who asks the question,
          such as a school friend or someone who works in the cafeteria.
          The wording of the question could introduce response bias.
          Students would likely respond differently if asked
          <q>Do you like the food in the cafeteria?</q>
          versus ``The food in the cafeteria is pretty bad, don't you think?"
        </p>
      </solution>
    </example>
    <assemblage>
      <title>Watch out for bias</title>
      <p>
        Undercoverage bias, non-response bias,
        and response bias can still exist within a random sample.
        Always determine how a sample was chosen,
        ask what proportion of people failed to respond,
        and critically examine the wording of the questions.
      </p>
    </assemblage>
    <p>
      When there is no bias in a sample,
      increasing the sample size tends to increase the precision and reliability of the estimate.
      When a sample is biased,
      it may be impossible to decipher helpful information from the data,
      even if the sample is very large.
    </p>
    <exercise>
      <statement>
        <p>
          A researcher sends out questionnaires to 50 randomly selected households in a particular town asking whether or not they support the addition of a traffic light in their neighborhood.
          Because only 20% of the questionnaires are returned,
          she decides to mail questionnaires to 50 more randomly selected households in the same neighborhood.
          Comment on the usefulness of this approach.
        </p>
      </statement>
      <answer>
        <p>
          The researcher should be concerned about non-response bias,
          and sampling more people will not eliminate this issue.
          The same type of people that did not respond to the first survey are likely not going to respond to the second survey.
          Instead, she should make an effort to reach out to the households from the original sample that did not respond and solicit their feedback,
          possibly by going door-to-door.
        </p>
      </answer>
    </exercise>
    <p>
          <idx><h>sample</h><h>random sample</h></idx>
          <idx><h>population</h></idx>
          <idx><h>sample</h></idx>
    </p>
  </subsection>
  <subsection xml:id="threeSamplingMethods">
    <title>Simple, systematic, stratified, cluster, and multistage sampling</title>
    <p>
      Almost all statistical methods for observational data rely on a sample being random and unbiased.
      When a sample is collected in a biased way,
      these statistical methods will not generally produce reliable information about the population.
    </p>
    <p>
      The idea of a simple random sample was introduced in the last section.
      Here we provide a more technical treatment of this method and introduce four new random sampling methods:
      systematic, stratified, cluster, and multistage.<fn>
      Multistage sampling is not part of the AP syllabus.
      </fn> <xref ref="simple_systematic">Figure</xref>
      provides a graphical representation of simple versus systematic sampling while <xref ref="stratified_cluster_multistage">Figure</xref>
      provides a graphical representation of stratified,
      cluster, and multistage sampling.
    </p>
    <figure xml:id="simple_systematic">
      <caption>Examples of simple random sampling and systematic sampling. In the top panel, simple random sampling was used to randomly select 18 cases. In the lower panel, systematic random sampling was used to select every 7th individual.</caption>
      \Figures{0.9}{samplingMethodsFigure}{simple_systematic}
    </figure>
    <p>
      <em>Simple random sampling</em><idx><h>sample</h><h>simple random sampling</h></idx> is probably the most intuitive form of random sampling.
      Consider the salaries of Major League Baseball (MLB) players,
      where each player is a member of one of the league's 30 teams.
      For the 2019 season, N, the population size or total number of players, is 750.
      To take a simple random sample of <em>n</em>
      = 120 of these baseball players and their salaries,
      we could number each player from 1 to 750.
      Then we could randomly select 120 numbers between 1 and 750
      (without replacement)
      using a random number generator or random digit table.
      The players with the selected numbers would comprise our sample.
    </p>
    <p>
      Two properties are always true in a simple random sample:
      <ol>
        <li>
          <p>
            Each case in the population has an equal chance of being included in the sample.
          </p>
        </li>
        <li>
          <p>
            Each <em>group</em> of <em>n</em>
            cases has an equal chance of making up the sample.
          </p>
        </li>
      </ol>
    </p>
    <p>
      The statistical methods in this book focus on data collected using simple random sampling.
      Note that Property 2 <mdash/> that each group of <em>n</em>
      cases has an equal chance making up the sample <mdash/> is not true for the remaining four sampling techniques.
      As you read each one, consider why.
    </p>
    <p>
      Though less common than simple random sampling,
      <em>systematic sampling</em><idx><h>sample</h><h>systematic sampling</h></idx> is sometimes used when there exists a convenient list of all of the individuals of the population.
      Suppose we have a roster with the names of all the MLB players from the 2019 season.
      To take a systematic random sample,
      number them from 1 to 750.
      Select one random number between 1 and 750 and let that player be the first individual in the sample.
      Then, depending on the desired sample size,
      select every 10th number or 20th number,
      for example, to arrive at the sample.<fn>
      If we want a sample of size <em>n</em> = 150,
      it would make sense to select every 5th player since \mbox{<m>750/150 = 5</m>.} Suppose we randomly select the number 741.
      Then player 741, 746, 1, 6, 11,
      <m>\cdots</m> , 731, and 736 would make up the sample.
      </fn> If there are no patterns in the salaries based on the numbering then this could be a reasonable method.
    </p>
    <example>
      <statement>
        <p>
          A systematic sample is not the same as a simple random sample.
          Provide an example of a sample that can come from a simple random sample but not from a systematic random sample.
        </p>
      </statement>
      <solution>
        <p>
          Answers can vary.
          If we take a sample of size 3, then it is possible that we could sample players numbered 1, 2, and 3 in a simple random sample.
          Such a sample would be impossible from a systematic sample.
          Property<nbsp/>2 of simple random samples does not hold for other types of random samples.
        </p>
      </solution>
    </example>
    <p>
      Sometimes there is a variable that is known to be associated with the quantity we want to estimate.
      In this case, a stratified random sample might be selected.
      <em>Stratified sampling</em><idx><h>sample</h><h>stratified sampling</h></idx> is a divide-and-conquer sampling strategy.
      The population is divided into groups called <term>strata</term>.
          <idx><h>sample</h><h>strata</h></idx>
      The strata are chosen so that similar cases are grouped together and a sampling method,
      usually simple random sampling,
      is employed to select a certain number or a certain proportion of the whole within each stratum.
      In the baseball salary example,
      the 30 teams could represent the strata;
      some teams have a lot more money
      (we're looking at you, Yankees).
    </p>
    <figure xml:id="stratified_cluster_multistage">
      <caption>Examples of stratified, cluster, and multistage sampling. In the top panel, stratified sampling was used: cases were grouped into strata, and then simple random sampling was employed within each stratum. In the middle panel, cluster sampling was used, where data were binned into nine cluster and three clusters were randomly selected. In the bottom panel, multistage sampling was used. Data were binned into the nine clusters, three of the cluster were randomly selected, and then six cases were randomly sampled in each of the three selected clusters.</caption>
      \Figures{0.85}{samplingMethodsFigure}{stratified_cluster_multistage}
    </figure>
    <example>
      <statement>
        <p>
          For this baseball example,
          briefly explain how to select a stratified random sample of size <em>n</em> = 120.
        </p>
      </statement>
      <answer>
        <p>
          Each team can serve as a stratum,
          and we could take a simple random sample of 4 players from each of the 30 teams,
          yielding a sample of 120 players.
        </p>
      </answer>
    </example>
    <p>
      Stratified sampling is inherently different than simple random sampling.
      For example,
      the stratified sampling approach described would make it impossible for the entire Yankees team to be included in the sample.
    </p>
    <example>
      <statement>
        <p>
          Stratified sampling is especially useful when the cases in each stratum are very similar
          <em>with respect to the outcome of interest</em>.
          Why is it good for cases within each stratum to be very similar?
        </p>
      </statement>
      <answer>
        <p>
          We should get a more stable estimate for the subpopulation in a stratum if the cases are very similar.
          These improved estimates for each subpopulation will help us build a reliable estimate for the full population.
          For example, in a simple random sample,
          it is possible that just by random chance we could end up with proportionally too many Yankees players in our sample,
          thus overestimating the true average salary of all MLB players.
          A stratified random sample can assure proportional representation from each team.
        </p>
      </answer>
    </example>
    <p>
      Next, let's consider a sampling technique that randomly selects groups of people.
      <em>Cluster sampling</em><idx><h>sample</h><h>cluster sampling</h></idx> is much like simple random sampling,
      but instead of randomly selecting <em>individuals</em>,
      we randomly select groups or <term>clusters</term>.
      Unlike stratified sampling,
      cluster sampling is most helpful when there is a lot of case-to-case variability within a cluster but the clusters themselves don't look very different from one another.
      That<nbsp/>is, we expect individual strata to be
      <term>homogeneous</term> (self-similar),
      while we expect individual clusters to be
      <term>heterogeneous</term>
      (diverse) with respect to the variable of interest.
    </p>
    <p>
      Sometimes cluster sampling can be a more economical random sampling technique than the alternatives.
      For example, if neighborhoods represented clusters,
      this sampling method works best when each neighborhood is very diverse.
      Because each neighborhood itself encompasses diversity,
      a cluster sample can reduce the time and cost associated with data collection,
      because the interviewer would need only go to some of the neighborhoods rather than to all parts of a city,
      in order to collect a useful sample.
    </p>
    <p>
      <em>Multistage sampling</em>,
          <idx><h>sample</h><h>multistage sampling</h></idx>
      also called <em>multistage cluster sampling</em>,
          <idx><h>sample</h><h>multistage cluster sampling</h></idx>
      is a two (or more) step strategy.
      The first step is to take a cluster sample, as described above.
      Then, instead of including all of the individuals in these clusters in our sample,
      a second sampling method,
      usually simple random sampling,
      is employed within each of the selected clusters.
      In the neighborhood example,
      we could first randomly select some number of neighborhoods and then take a simple random sample from just those selected neighborhoods.
      As seen in <xref ref="stratified_cluster_multistage">Figure</xref>,
      stratified sampling requires observations to be sampled from <em>every</em> stratum.
      Multistage sampling selects observations <em>only</em>
      from those clusters that were randomly selected in the first step.
    </p>
    <p>
      It is also possible to have more than two steps in multistage sampling.
      Each cluster may be naturally divided into subclusters.
      For example, each neighborhood could be divided into streets.
      To take a three-stage sample,
      we could first select some number of clusters (neighborhoods),
      and then,
      within the selected clusters,
      select some number of subclusters
      (streets).
      Finally, we could select some number of individuals from each of the selected streets.
    </p>
    <example>
      <statement>
        <p>
          Suppose we are interested in estimating the proportion of students at a certain school that have part-time jobs.
          It is believed that older students are more likely to work than younger students.
          What sampling method should be employed?
          Describe how to collect such a sample to get a sample size of 60.
        </p>
      </statement>
      <solution>
        <p>
          Because grade level affects the likelihood of having a part-time job,
          we should take a stratified random sample.
          To do this, we can take a simple random sample of 15 students from each grade.
          This will give us equal representation from each grade.
          Note: in a simple random sample,
          just by random chance we might get too many students who are older or younger,
          which could make the estimate too high or too low.
          Also, there are no well-defined clusters in this example.
          We<nbsp/>wouldn't want to use the grades as clusters and sample everyone from a couple of the grades.
          This would create too large a sample and would not give us the nice representation from each grade afforded by the stratified random sample.
        </p>
      </solution>
    </example>
    <example>
      <statement>
        <p>
          Suppose we are interested in estimating the malaria rate in a densely tropical portion of rural Indonesia.
          We learn that there are 30 villages in that part of the Indonesian jungle,
          each more or less similar to the next.
          Our goal is to test 150 individuals for malaria.
          What sampling method should be employed?
        </p>
      </statement>
      <solution>
        <p>
          A simple random sample would likely draw individuals from all 30 villages,
          which could make data collection extremely expensive.
          Stratified sampling would be a challenge since it is unclear how we would build strata of similar individuals.
          However, multistage cluster sampling seems like a very good idea.
          First, we might randomly select half the villages,
          then randomly select 10 people from each.
          This would probably reduce our data collection costs substantially in comparison to a simple random sample and would still give us reliable information.
        </p>
      </solution>
    </example>
    <assemblage>
      <title>Advanced sampling techniques require advanced methods</title>
      <p>
        {The methods of inference covered in this book generally only apply to simple random samples.
        More advanced analysis techniques are required for systematic,
        stratified, cluster, and multistage random sampling.}
      </p>
    </assemblage>
  </subsection>
  <subsection>
    <title>Section summary</title>
    <ul>
      <li>
        <p>
          In an <term>observational study</term>,
          one must always consider the existence of
          <em>confounding factors</em>.
            <idx><h>confounding factor</h></idx>
        A confounding factor is a
          <q>spoiler variable</q>
          that could explain an observed relationship between the explanatory variable and the response.
          Remember: For a variable to be confounding it must be associated with both the explanatory variable
          <em>and</em> the response variable.
        </p>
      </li>
      <li>
        <p>
          When taking a sample from a population,
          avoid <em>convenience samples</em>
            <idx><h>convenience sample</h></idx>
          and <em>volunteer samples</em>,
            <idx><h>volunteer sample</h></idx>
          which likely introduce bias.
          Instead, use a <term>random</term> sampling method.
        </p>
      </li>
      <li>
        <p>
          Generalizations from a sample can be made to a population only if the sample is random.
          Furthermore,
          the generalization can be made only to the population from which the sample was randomly selected,
          not to a larger or different population.
        </p>
      </li>
      <li>
        <p>
          Random sampling from the entire population of interest avoids the problem of
          <term>undercoverage bias</term>.
          However, <term>response bias</term>
          and <term>non-response</term>
          bias can be present in any type of sample, random or not.
        </p>
      </li>
      <li>
        <p>
          In a <term>simple random sample</term>,
          every <em>individual</em> as well as every
          <em>group of individuals</em>
          has the same probability of being in the sample.
          A common way to select a simple random sample is to number each individual of the population from 1 to N. Using a random digit table or a random number generator,
          numbers are randomly selected without replacement and the corresponding individuals become part of the sample.
        </p>
      </li>
      <li>
        <p>
          A <term>systematic random sample</term>
          involves choosing from of a population using a random starting point,
          and then selecting members according to a fixed, periodic interval
          (such as every 10th member).
        </p>
      </li>
      <li>
        <p>
          A <term>stratified random sample</term>
          involves randomly sampling from
          <em>every</em> <term>strata</term>,
          where the strata should correspond to a variable thought to be associated with the variable of interest.
          This ensures that the sample will have appropriate representation from each of the different strata and reduces variability in the sample estimates.
        </p>
      </li>
      <li>
        <p>
          A <term>cluster random sample</term>
          involves randomly selecting a set of
          <term>clusters</term>, or groups,
          and then collecting data on all individuals in the selected clusters.
          This can be useful when sampling clusters is more convenient and less expensive than sampling individuals,
          and it is an effective strategy when each cluster is approximately representative of the population.
        </p>
      </li>
      <li>
        <p>
          Remember: <em>Individual strata should be homogeneous (self-similar),
          while individual clusters should be heterogeneous (diverse)</em>.
          For example,
          if smoking is correlated with what is being estimated,
          let one stratum be all smokers and the other be all non-smokers,
          then randomly select an appropriate number of <em>individuals</em>
          from <em>each</em> strata.
          Alternately,
          if age is correlated with the variable being estimated,
          one could randomly select a <em>subset</em> of clusters,
          where each cluster has mixed age groups.
        </p>
      </li>
    </ul>
  </subsection>
</section>